Question = question_labels[i],
Group = "Employees",
Response = employee_data[[col_name]]
)
plot_data_long <- rbind(plot_data_long, question_data)
}
# Add resident data
for (i in 1:8) {
col_name <- paste0("Q1_", i)
question_data <- data.frame(
Question = question_labels[i],
Group = "Residents",
Response = resident_data[[col_name]]
)
plot_data_long <- rbind(plot_data_long, question_data)
}
# Add tourist data
for (i in 1:8) {
col_name <- paste0("Q1_", i)
question_data <- data.frame(
Question = question_labels[i],
Group = "Tourists",
Response = tourist_data[[col_name]]
)
plot_data_long <- rbind(plot_data_long, question_data)
}
# Calculate proportions for each response value by group
response_props <- plot_data_long %>%
group_by(Group, Response) %>%
summarise(Count = n(), .groups = "drop") %>%
group_by(Group) %>%
mutate(Proportion = Count / sum(Count))
# Create the comparison plot
p <- ggplot(response_props, aes(x = Response, y = Proportion, fill = Group)) +
geom_bar(stat = "identity", position = position_dodge(width = 0.8), width = 0.7) +
scale_fill_manual(values = c("#4BA7C5", "#FF8B98", "#63C988")) +  # More saturated colors
labs(
title = "Response Distribution Comparison Across Groups",
x = "Response Level (1=Extremely Unlikely, 5=Extremely Likely)",
y = "Proportion"
) +
theme_minimal() +
theme(
plot.background = element_rect(fill = "white", color = NA),
panel.background = element_rect(fill = "white", color = NA),
panel.grid.major.y = element_line(color = "gray90"),
panel.grid.minor.y = element_blank(),
panel.grid.major.x = element_line(color = "gray90"),
panel.grid.minor.x = element_blank(),
plot.title = element_text(hjust = 0.5, face = "bold", size = 14),
axis.text = element_text(color = "black"),
axis.title = element_text(color = "black", face = "bold"),
legend.position = "top",
legend.title = element_text(face = "bold")
) +
scale_y_continuous(labels = scales::percent_format(accuracy = 1))
# Save the plot
ggsave("response_distribution_comparison.png", p, width = 10, height = 6)
cat("\nResponse distribution comparison plot has been saved as 'response_distribution_comparison.png'\n")
# Create comparison histogram plot
plot_data_long <- data.frame()
# Add employee data
for (i in 1:8) {
col_name <- paste0("Q1_", i)
question_data <- data.frame(
Question = question_labels[i],
Group = "Employees",
Response = employee_data[[col_name]]
)
plot_data_long <- rbind(plot_data_long, question_data)
}
# Add resident data
for (i in 1:8) {
col_name <- paste0("Q1_", i)
question_data <- data.frame(
Question = question_labels[i],
Group = "Residents",
Response = resident_data[[col_name]]
)
plot_data_long <- rbind(plot_data_long, question_data)
}
# Add tourist data
for (i in 1:8) {
col_name <- paste0("Q1_", i)
question_data <- data.frame(
Question = question_labels[i],
Group = "Tourists",
Response = tourist_data[[col_name]]
)
plot_data_long <- rbind(plot_data_long, question_data)
}
# Calculate proportions for each response value by group
response_props <- plot_data_long %>%
group_by(Group, Response) %>%
summarise(Count = n(), .groups = "drop") %>%
group_by(Group) %>%
mutate(Proportion = Count / sum(Count))
# Create the comparison plot
p <- ggplot(response_props, aes(x = Response, y = Proportion, fill = Group)) +
geom_bar(stat = "identity", position = position_dodge(width = 0.8), width = 0.7) +
scale_fill_manual(values = c("#4BA7C5", "#FF8B98", "#63C988")) +  # More saturated colors
labs(
title = "Response Distribution Across Groups",
subtitle = paste0(
"Aggregated responses across 8 climate impact questions:\n",
"Tourist numbers, Peak/Off-season changes, Outdoor activities,\n",
"Business closures, Health risks, Energy costs, Water stress"
),
x = "Response Level (1=Extremely Unlikely, 5=Extremely Likely)",
y = "Proportion of Responses",
caption = paste0(
"Based on responses from ", n_employees, " Employees, ",
n_residents, " Residents, and ", n_tourists, " Tourists"
)
) +
theme_minimal() +
theme(
plot.background = element_rect(fill = "white", color = NA),
panel.background = element_rect(fill = "white", color = NA),
panel.grid.major.y = element_line(color = "gray90"),
panel.grid.minor.y = element_blank(),
panel.grid.major.x = element_line(color = "gray90"),
panel.grid.minor.x = element_blank(),
plot.title = element_text(hjust = 0.5, face = "bold", size = 14),
plot.subtitle = element_text(hjust = 0.5, size = 10),
plot.caption = element_text(hjust = 0.5, size = 9),
axis.text = element_text(color = "black"),
axis.title = element_text(color = "black", face = "bold"),
legend.position = "top",
legend.title = element_text(face = "bold")
) +
scale_y_continuous(labels = scales::percent_format(accuracy = 1))
# Add text showing total number of responses
total_responses <- nrow(plot_data_long)
# Save the plot
ggsave("response_distribution_comparison.png", p, width = 10, height = 6)
cat("\nResponse distribution comparison plot has been saved as 'response_distribution_comparison.png'\n")
library(plotly)
library(dplyr)
# Read the feature importance data
feature_importance <- read.csv("feature_importance.csv")
setwd("/Users/davidwhyatt/Documents/GitHub/PhDMelodySet")
library(plotly)
library(dplyr)
# Read the feature importance data
feature_importance <- read.csv("feature_importance.csv")
# Create interactive plot
p <- plot_ly(feature_importance,
x = ~reorder(feature, desc(importance)),
y = ~importance,
type = "bar",
text = ~round(importance, 4),
textposition = "auto",
hoverinfo = "text",
texttemplate = "%{text}") %>%
layout(title = "Feature Importance",
xaxis = list(title = "Features",
tickangle = 45),
yaxis = list(title = "Importance"),
margin = list(b = 150)) %>%
config(displayModeBar = FALSE)
p
# Read the CSV files
original_features <- read.csv("/Users/davidwhyatt/Documents/GitHub/PhDMelodySet/original_mel_miq_mels.csv")
miq_features <- read.csv("/Users/davidwhyatt/Documents/GitHub/PhDMelodySet/miq_mels.csv")
# Keep melody ID column
melody_id <- original_features$melody_id
# Drop non-numeric columns before subtraction
original_features <- original_features[sapply(original_features, is.numeric)]
miq_features <- miq_features[sapply(miq_features, is.numeric)]
# Calculate differences between dataframes
feature_diffs <- miq_features - original_features
# Find zero variance columns
zero_var_cols <- feature_diffs %>%
summarise(across(everything(), var)) %>%
pivot_longer(everything()) %>%
filter(value == 0) %>%
pull(name)
# Print dropped columns
if(length(zero_var_cols) > 0) {
cat("Dropping zero variance features:", paste(zero_var_cols, collapse=", "), "\n")
}
# Drop zero variance columns and tempo features
feature_diffs <- feature_diffs %>%
select(-starts_with("duration_features.tempo")) %>%
select(-any_of(zero_var_cols))
# Read the CSV files
original_features <- read.csv("/Users/davidwhyatt/Documents/GitHub/PhDMelodySet/original_mel_miq_mels.csv")
miq_features <- read.csv("/Users/davidwhyatt/Documents/GitHub/PhDMelodySet/miq_mels.csv")
# Keep melody ID column
melody_id <- original_features$melody_id
# Drop non-numeric columns before subtraction
original_features <- original_features[sapply(original_features, is.numeric)]
miq_features <- miq_features[sapply(miq_features, is.numeric)]
# Calculate differences between dataframes
feature_diffs <- miq_features - original_features
# Find zero variance columns
zero_var_cols <- feature_diffs %>%
summarise(across(everything(), var)) %>%
pivot_longer(everything()) %>%
filter(value == 0) %>%
pull(name)
# Print dropped columns
if(length(zero_var_cols) > 0) {
cat("Dropping zero variance features:", paste(zero_var_cols, collapse=", "), "\n")
}
# Drop zero variance columns and tempo features
feature_diffs <- feature_diffs %>%
select(-starts_with("duration_features.tempo")) %>%
select(-any_of(zero_var_cols))
# Read the CSV files
original_features <- read.csv("/Users/davidwhyatt/Documents/GitHub/PhDMelodySet/original_mel_miq_mels.csv")
miq_features <- read.csv("/Users/davidwhyatt/Documents/GitHub/PhDMelodySet/miq_mels.csv")
# Load required libraries first
library(tidyverse)
library(caret)
library(randomForest)
library(ggplot2)
# Keep melody ID column
melody_id <- original_features$melody_id
# Drop non-numeric columns before subtraction
original_features <- original_features[sapply(original_features, is.numeric)]
miq_features <- miq_features[sapply(miq_features, is.numeric)]
# Calculate differences between dataframes
feature_diffs <- miq_features - original_features
# Find zero variance columns
zero_var_cols <- feature_diffs %>%
summarise(across(everything(), var)) %>%
pivot_longer(everything()) %>%
filter(value == 0) %>%
pull(name)
# Print dropped columns
if(length(zero_var_cols) > 0) {
cat("Dropping zero variance features:", paste(zero_var_cols, collapse=", "), "\n")
}
# Convert feature_diffs to tibble and drop zero variance columns and tempo features
feature_diffs <- as_tibble(feature_diffs) %>%
select(-matches("duration_features.tempo")) %>%
select(-all_of(zero_var_cols))
# Read the CSV files
original_features <- read.csv("/Users/davidwhyatt/Documents/GitHub/PhDMelodySet/original_mel_miq_mels.csv")
miq_features <- read.csv("/Users/davidwhyatt/Documents/GitHub/PhDMelodySet/miq_mels.csv")
# Load required libraries first
library(tidyverse)
library(caret)
library(randomForest)
library(ggplot2)
# Keep melody ID column
melody_id <- original_features$melody_id
# Drop non-numeric columns before subtraction
original_features <- original_features[sapply(original_features, is.numeric)]
miq_features <- miq_features[sapply(miq_features, is.numeric)]
# Calculate differences between dataframes
feature_diffs <- miq_features - original_features
# Find zero variance columns
zero_var_cols <- feature_diffs %>%
summarise(across(everything(), var)) %>%
pivot_longer(everything()) %>%
filter(value == 0) %>%
pull(name)
# Print dropped columns
if(length(zero_var_cols) > 0) {
cat("Dropping zero variance features:", paste(zero_var_cols, collapse=", "), "\n")
}
# Convert feature_diffs to tibble and drop zero variance columns and tempo features
feature_diffs <- as_tibble(feature_diffs) %>%
select(-matches("duration_features.tempo")) %>%
select(-all_of(zero_var_cols))
# Read the CSV files
original_features <- read.csv("/Users/davidwhyatt/Documents/GitHub/PhDMelodySet/original_mel_miq_mels.csv")
miq_features <- read.csv("/Users/davidwhyatt/Documents/GitHub/PhDMelodySet/miq_mels.csv")
# Load required libraries first
library(tidyverse)
library(caret)
library(randomForest)
library(ggplot2)
# Keep melody ID column
melody_id <- original_features$melody_id
# Drop non-numeric columns before subtraction
original_features <- original_features[sapply(original_features, is.numeric)]
miq_features <- miq_features[sapply(miq_features, is.numeric)]
# Calculate differences between dataframes
feature_diffs <- miq_features - original_features
# Find zero variance columns
zero_var_cols <- names(feature_diffs)[apply(feature_diffs, 2, var) == 0]
# Print dropped columns
if(length(zero_var_cols) > 0) {
cat("Dropping zero variance features:", paste(zero_var_cols, collapse=", "), "\n")
}
# Remove tempo features and zero variance columns using base R
tempo_cols <- grep("duration_features.tempo", names(feature_diffs), value = TRUE)
cols_to_remove <- unique(c(tempo_cols, zero_var_cols))
feature_diffs <- feature_diffs[, !names(feature_diffs) %in% cols_to_remove]
# Handle infinite and missing values
feature_diffs[is.infinite(feature_diffs)] <- NA
# Read the CSV files
original_features <- read.csv("/Users/davidwhyatt/Documents/GitHub/PhDMelodySet/original_mel_miq_mels.csv")
miq_features <- read.csv("/Users/davidwhyatt/Documents/GitHub/PhDMelodySet/miq_mels.csv")
# Load required libraries first
library(tidyverse)
library(caret)
library(randomForest)
library(ggplot2)
# Keep melody ID column
melody_id <- original_features$melody_id
# Drop non-numeric columns before subtraction
original_features <- original_features[sapply(original_features, is.numeric)]
miq_features <- miq_features[sapply(miq_features, is.numeric)]
# Calculate differences between dataframes
feature_diffs <- as.data.frame(miq_features - original_features)
# Find zero variance columns
zero_var_cols <- names(feature_diffs)[apply(feature_diffs, 2, var) == 0]
# Print dropped columns
if(length(zero_var_cols) > 0) {
cat("Dropping zero variance features:", paste(zero_var_cols, collapse=", "), "\n")
}
# Remove tempo features and zero variance columns using base R
tempo_cols <- grep("duration_features.tempo", names(feature_diffs), value = TRUE)
cols_to_remove <- unique(c(tempo_cols, zero_var_cols))
feature_diffs <- feature_diffs[, !names(feature_diffs) %in% cols_to_remove]
# Handle infinite and missing values
feature_diffs <- as.data.frame(lapply(feature_diffs, function(x) {
x[is.infinite(x)] <- NA
x[is.na(x)] <- 0
x
}))
# Scale the features
feature_diffs <- scale(feature_diffs)
# Perform PCA
pca <- prcomp(feature_diffs)
# Print summary of PCA
print(summary(pca))
# Plot scree plot
pdf("R/rf_scree_plot.pdf")
plot(pca$sdev^2/sum(pca$sdev^2), type="b",
xlab="Principal Component",
ylab="Proportion of Variance Explained",
main="Scree Plot")
dev.off()
# Load required libraries
library(randomForest)
library(tidyverse)
library(caret)
library(ggplot2)
# Load in the original item bank file
item_bank <-
read_csv("/Users/davidwhyatt/Documents/GitHub/PhDMelodySet/item-bank.csv") |>
rename(item_id = id)
# Read in the participant responses
df <-
read_csv("/Users/davidwhyatt/Downloads/miq_trials.csv", n_max = 1e6) |>
filter(test == "mdt") |>
left_join(item_bank |> select(- c("discrimination", "difficulty", "guessing", "inattention")), by = "item_id")
# Read the CSV files
original_features <- read.csv("/Users/davidwhyatt/Documents/GitHub/PhDMelodySet/original_mel_miq_mels.csv")
miq_features <- read.csv("/Users/davidwhyatt/Documents/GitHub/PhDMelodySet/miq_mels.csv")
# Load required libraries first
library(tidyverse)
library(caret)
library(randomForest)
library(ggplot2)
library(dplyr)
# Keep melody ID column
melody_id <- original_features$melody_id
# Drop non-numeric columns before subtraction
original_features <- original_features[sapply(original_features, is.numeric)]
miq_features <- miq_features[sapply(miq_features, is.numeric)]
# Calculate differences between dataframes
feature_diffs <- as.data.frame(miq_features - original_features)
# Find zero variance columns
zero_var_cols <- names(feature_diffs)[apply(feature_diffs, 2, var) == 0]
# Print dropped columns
if(length(zero_var_cols) > 0) {
cat("Dropping zero variance features:", paste(zero_var_cols, collapse=", "), "\n")
}
# Remove tempo features and zero variance columns using base R
tempo_cols <- grep("duration_features.tempo", names(feature_diffs), value = TRUE)
cols_to_remove <- unique(c(tempo_cols, zero_var_cols))
feature_diffs <- feature_diffs[, !names(feature_diffs) %in% cols_to_remove]
# Handle infinite and missing values
feature_diffs <- as.data.frame(lapply(feature_diffs, function(x) {
x[is.infinite(x)] <- NA
x[is.na(x)] <- 0
x
}))
# Scale the features
feature_diffs <- scale(feature_diffs)
# Perform PCA
pca <- prcomp(feature_diffs)
# Print summary of PCA
print(summary(pca))
# Plot scree plot
pdf("R/rf_scree_plot.pdf")
plot(pca$sdev^2/sum(pca$sdev^2), type="b",
xlab="Principal Component",
ylab="Proportion of Variance Explained",
main="Scree Plot")
dev.off()
# Load required libraries
library(randomForest)
library(tidyverse)
library(caret)
library(ggplot2)
# Load in the original item bank file
item_bank <-
read_csv("/Users/davidwhyatt/Documents/GitHub/PhDMelodySet/item-bank.csv") |>
rename(item_id = id)
# Read in the participant responses
df <-
read_csv("/Users/davidwhyatt/Downloads/miq_trials.csv", n_max = 1e6) |>
filter(test == "mdt") |>
left_join(item_bank |> select(- c("discrimination", "difficulty", "guessing", "inattention")), by = "item_id")
# Read the CSV files
original_features <- read.csv("/Users/davidwhyatt/Documents/GitHub/PhDMelodySet/original_mel_miq_mels.csv")
miq_features <- read.csv("/Users/davidwhyatt/Documents/GitHub/PhDMelodySet/miq_mels.csv")
# Keep melody ID column
melody_id <- original_features$melody_id
# Drop non-numeric columns before subtraction
original_features <- original_features[sapply(original_features, is.numeric)]
miq_features <- miq_features[sapply(miq_features, is.numeric)]
# Calculate differences between dataframes
feature_diffs <- miq_features - original_features
# Find zero variance columns
zero_var_cols <- feature_diffs %>%
summarise(across(everything(), var)) %>%
pivot_longer(everything()) %>%
filter(value == 0) %>%
pull(name)
# Print dropped columns
if(length(zero_var_cols) > 0) {
cat("Dropping zero variance features:", paste(zero_var_cols, collapse=", "), "\n")
}
# Drop zero variance columns and tempo features
feature_diffs <- feature_diffs %>%
select(-starts_with("duration_features.tempo")) %>%
select(-any_of(zero_var_cols))
# Load in the original item bank file
item_bank <-
read_csv("/Users/davidwhyatt/Documents/GitHub/PhDMelodySet/item-bank.csv") |>
rename(item_id = id)
# Read in the participant responses (first 1e6, as too many will throttle
# my cpu)
df <-
read_csv("/Users/davidwhyatt/Downloads/miq_trials.csv", n_max = 1e6) |>
filter(test == "mdt") |>
left_join(item_bank |> select(- c("discrimination", "difficulty", "guessing", "inattention")), by = "item_id")
# Read the CSV files
original_features <- read.csv("/Users/davidwhyatt/Documents/GitHub/PhDMelodySet/original_mel_miq_mels.csv")
miq_features <- read.csv("/Users/davidwhyatt/Documents/GitHub/PhDMelodySet/miq_mels.csv")
# Load required libraries first
library(tidyverse)
library(caret)
library(randomForest)
library(ggplot2)
library(dplyr)
# Keep melody ID column
melody_id <- original_features$melody_id
# Drop non-numeric columns before subtraction
original_features <- original_features[sapply(original_features, is.numeric)]
miq_features <- miq_features[sapply(miq_features, is.numeric)]
# Calculate differences between dataframes
feature_diffs <- as.data.frame(miq_features - original_features)
# Find zero variance columns
zero_var_cols <- names(feature_diffs)[apply(feature_diffs, 2, var) == 0]
# Print dropped columns
if(length(zero_var_cols) > 0) {
cat("Dropping zero variance features:", paste(zero_var_cols, collapse=", "), "\n")
}
# Remove tempo features and zero variance columns using base R
tempo_cols <- grep("duration_features.tempo", names(feature_diffs), value = TRUE)
cols_to_remove <- unique(c(tempo_cols, zero_var_cols))
feature_diffs <- feature_diffs[, !names(feature_diffs) %in% cols_to_remove]
# Handle infinite and missing values
feature_diffs <- as.data.frame(lapply(feature_diffs, function(x) {
x[is.infinite(x)] <- NA
x[is.na(x)] <- 0
x
}))
# Scale the features
feature_diffs <- scale(feature_diffs)
# Perform PCA
pca <- prcomp(feature_diffs)
# Print summary of PCA
print(summary(pca))
# Plot scree plot
pdf("R/rf_scree_plot.pdf")
plot(pca$sdev^2/sum(pca$sdev^2), type="b",
xlab="Principal Component",
ylab="Proportion of Variance Explained",
main="Scree Plot")
dev.off()
# Load required libraries
library(randomForest)
library(tidyverse)
library(caret)
library(ggplot2)
# Load in the original item bank file
item_bank <- read_csv("/Users/davidwhyatt/Documents/GitHub/PhDMelodySet/item-bank.csv") %>%
rename(item_id = id) %>%
select(-discrimination, -difficulty, -guessing, -inattention)
# Load required libraries
library(glmnet)
library(tidyverse)
# Load in the original item bank file
item_bank <-
read_csv("/Users/davidwhyatt/Documents/GitHub/PhDMelodySet/item-bank.csv") |>
rename(item_id = id)
# Read in the participant responses
df <-
read_csv("/Users/davidwhyatt/Downloads/miq_trials.csv", n_max = 1e6) |>
filter(test == "mdt") |>
left_join(item_bank |> select(- c("discrimination", "difficulty", "guessing", "inattention")), by = "item_id")
