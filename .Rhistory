View(features_scaled)
# Perform PCA using PCAtest
library(PCAtest)
pca <- pcatest(features_scaled)
devtools::install_github("arleyc/PCAtest"), force = TRUE
devtools::install_github("arleyc/PCAtest", force = TRUE)
# Read in the features data
item_features <- read.csv("item_features.csv")
# Remove melody_id column and any non-numeric columns
features_numeric <- item_features[, sapply(item_features, is.numeric)]
# Remove any rows with NA values
features_numeric <- na.omit(features_numeric)
# Scale the features before PCA
features_numeric <- features_numeric[, !names(features_numeric) %in% "tonality_features.inscale"]
features_scaled <- scale(features_numeric)
View(features_scaled)
# Perform PCA using PCAtest
library(PCAtest)
pca <- pcatest(features_scaled)
library(PCAtest)
pca <- pcatest(features_scaled)
# Read in the features data
item_features <- read.csv("item_features.csv")
# Remove melody_id column and any non-numeric columns
features_numeric <- item_features[, sapply(item_features, is.numeric)]
# Remove any rows with NA values
features_numeric <- na.omit(features_numeric)
# Scale the features before PCA
features_numeric <- features_numeric[, !names(features_numeric) %in% "tonality_features.inscale"]
features_scaled <- scale(features_numeric)
View(features_scaled)
# Create scree plot
plot(pca, type="scree")
# Perform PCA with bootstrapping and permutation tests
pca_res <- PCAtest(features_scaled, nboot = 1000, nperm = 1000, alpha = 0.05,
varcorr = TRUE, plot = TRUE)
View(pca_res)
# Print summary of results
print(summary(pca_res))
df2 <- features_numeric
pca_data <- prcomp(df2, scale = TRUE, center = TRUE, retx = T)
fviz_pca_var(pca_data,
repel = TRUE,
axes = c(1,2),
show.legend.text = F,)
install.packages("fviz")
install.packages("FactomineR")
install.packages("FactoMineR")
library(FactoMineR)
fviz_pca_var(pca_data,
repel = TRUE,
axes = c(1,2),
show.legend.text = F,)
library(factoextra)
install.packages("factoextra")
df2 <- features_numeric
pca_data <- prcomp(df2, scale = TRUE, center = TRUE, retx = T)
library(FactoMineR)
library(factoextra)
fviz_pca_var(pca_data,
repel = TRUE,
axes = c(1,2),
show.legend.text = F,)
fviz_pca_var(pca_data,
repel = TRUE,
axes = c(1,2),
show.legend.text = F,
geom = "point")
fviz_pca_var(pca_data,
repel = TRUE,
axes = c(1,2),
show.legend.text = F,
geom = c("point", "text"))
fviz_pca_var(pca_data,
repel = TRUE,
axes = c(1,2),
show.legend.text = F,
geom = "text")
# Create scree plot of PCA results
fviz_eig(pca_data,
addlabels = TRUE,
ylim = c(0, 50),
main = "Scree Plot of PCA Components",
ylab = "Percentage of explained variances",
xlab = "Principal Components")
install.packages("sebsilas/melsim")
library(remotes)
remotes::install_github("sebsilas/melsim")
# Read in the features data
item_features <- read.csv("item_features2.csv")
# Remove melody_id column and any non-numeric columns
features_numeric <- item_features[, sapply(item_features, is.numeric)]
# Remove any rows with NA values
features_numeric <- na.omit(features_numeric)
View(features_numeric)
# Log transform temperley_likelihood
features_numeric$tonality_features.temperley_likelihood <- log(features_numeric$tonality_features.temperley_likelihood)
# Drop inscale column
features_numeric$tonality_features.inscale <- NULL
# Drop tempo as it is constant
features_numeric$duration_features.tempo <- NULL
# Scale the features before PCA
features_scaled <- scale(features_numeric)
View(features_scaled)
library(PCAtest)
# Perform PCA with bootstrapping and permutation tests
pca_res <- PCAtest(features_scaled, nboot = 1000, nperm = 1000, alpha = 0.05,
varcorr = TRUE, plot = TRUE)
View(pca_res)
# Print summary of results
print(summary(pca_res))
df2 <- features_numeric
pca_data <- prcomp(df2, scale = TRUE, center = TRUE, retx = T)
library(FactoMineR)
library(factoextra)
fviz_pca_var(pca_data,
repel = TRUE,
axes = c(1,2),
show.legend.text = F,
geom = "text")
library(FactoMineR)
library(factoextra)
fviz_pca_var(pca_data,
repel = TRUE,
axes = c(1,2),
show.legend.text = F,
geom = "text")
fviz_pca_var(pca_data,
repel = TRUE,
axes = c(1,2),
show.legend.text = F,
geom = "point")
fviz_pca_var(pca_data,
repel = TRUE,
axes = c(1,2),
show.legend.text = F,
geom = "label")
fviz_pca_var(pca_data,
repel = TRUE,
axes = c(1,2),
show.legend.text = F,
geom = "text")
# Create a mapping of old to new names
old_names <- colnames(features_scaled)
new_names <- paste0("V", seq_along(old_names))
name_mapping <- data.frame(
old_name = old_names,
new_name = new_names
)
# Rename the columns
colnames(features_scaled) <- new_names
df2 <- features_numeric
pca_data <- prcomp(df2, scale = TRUE, center = TRUE, retx = T)
library(FactoMineR)
library(factoextra)
fviz_pca_var(pca_data,
repel = TRUE,
axes = c(1,2),
show.legend.text = F,
geom = "text")
# Read in the features data
item_features <- read.csv("item_features2.csv")
# Remove melody_id column and any non-numeric columns
features_numeric <- item_features[, sapply(item_features, is.numeric)]
# Remove any rows with NA values
features_numeric <- na.omit(features_numeric)
View(features_numeric)
# Log transform temperley_likelihood
features_numeric$tonality_features.temperley_likelihood <- log(features_numeric$tonality_features.temperley_likelihood)
# Drop inscale column
features_numeric$tonality_features.inscale <- NULL
# Drop tempo as it is constant
features_numeric$duration_features.tempo <- NULL
# Scale the features before PCA
features_scaled <- scale(features_numeric)
View(features_scaled)
# Create a mapping of old to new names
old_names <- colnames(features_scaled)
new_names <- paste0("V", seq_along(old_names))
name_mapping <- data.frame(
old_name = old_names,
new_name = new_names
)
# Print the mapping
print("Variable name mapping:")
print(name_mapping)
# Rename the columns
colnames(features_scaled) <- new_names
df2 <- features_numeric
pca_data <- prcomp(df2, scale = TRUE, center = TRUE, retx = T)
library(FactoMineR)
library(factoextra)
fviz_pca_var(pca_data,
repel = TRUE,
axes = c(1,2),
show.legend.text = F,
geom = "text")
library(FactoMineR)
library(factoextra)
fviz_pca_var(pca_data,
repel = TRUE,
axes = c(1,2),
show.legend.text = F,
geom = "text",
col.var = "black",
label = new_names)
df2 <- features_numeric
pca_data <- prcomp(df2, scale = TRUE, center = TRUE, retx = T)
library(FactoMineR)
library(factoextra)
fviz_pca_var(pca_data,
repel = TRUE,
axes = c(1,2),
show.legend.text = F,
geom = "text",
col.var = "black",
label = new_names)
features_scaled
df2 <- features_scaled
pca_data <- prcomp(df2, scale = TRUE, center = TRUE, retx = T)
library(FactoMineR)
library(factoextra)
fviz_pca_var(pca_data,
repel = TRUE,
axes = c(1,2),
show.legend.text = F,
geom = "text")
# Determine optimal number of clusters using elbow method
wss <- numeric(15)  # Within sum of squares
for (i in 1:15) {
kmeans_fit <- kmeans(pca_data$x[,1:2], centers = i, nstart = 25)
wss[i] <- kmeans_fit$tot.withinss
}
# Plot elbow curve
plot(1:15, wss, type="b", pch = 19,
xlab="Number of Clusters",
ylab="Within Sum of Squares",
main="Elbow Method for Optimal k")
# Calculate silhouette scores for different k values
library(cluster)
sil_width <- numeric(14)
for(i in 2:15){
kmeans_fit <- kmeans(pca_data$x[,1:2], centers = i, nstart = 25)
ss <- silhouette(kmeans_fit$cluster, dist(pca_data$x[,1:2]))
sil_width[i-1] <- mean(ss[,3])
}
# Plot silhouette scores
plot(2:15, sil_width, type="b", pch = 19,
xlab="Number of Clusters",
ylab="Average Silhouette Width",
main="Silhouette Method for Optimal k")
# Perform k-means clustering with optimal k (adjust k based on plots)
k <- 3  # Adjust this value based on elbow and silhouette plots
final_kmeans <- kmeans(pca_data$x[,1:2], centers = k, nstart = 25)
# Visualize clusters on PCA plot
fviz_cluster(final_kmeans, data = pca_data$x[,1:2],
geom = "point",
ellipse.type = "convex",
main = "Cluster Plot on First Two PCs",
xlab = "PC1",
ylab = "PC2")
# Add cluster assignments to original data
cluster_assignments <- final_kmeans$cluster
print(table(cluster_assignments))
# Calculate cluster centers
cluster_centers <- aggregate(pca_data$x[,1:2],
by=list(Cluster=cluster_assignments),
FUN=mean)
print("Cluster Centers:")
print(cluster_centers)
# Load necessary libraries
library(randomForest)
library(caret)
# Load the data
data <- read.csv("item_features2.csv")
# Load the data
data <- read.csv("item_features2.csv")
# Read in trial data
trials <- read_csv("/Users/davidwhyatt/Downloads/miq_trials.csv", n_max = 1e4) |>
filter(test == "mdt")
# Load the data
data <- read.csv("item_features2.csv")
# Read in trial data
trials <- read.csv("/Users/davidwhyatt/Downloads/miq_trials.csv", n_max = 1e4) |>
filter(test == "mdt")
library(tidyverse)
trials <- read.csv("/Users/davidwhyatt/Downloads/miq_trials.csv", n_max = 1e4) |>
filter(test == "mdt")
trials <- read_csv("/Users/davidwhyatt/Downloads/miq_trials.csv", n_max = 1e4) |>
filter(test == "mdt")
# Calculate mean score for each item
score_by_item <- trials |>
group_by(item_id) |>
summarise(
score_item = mean(score)
)
# Join scores to feature data
data <- data |>
left_join(score_by_item, by = c("melody_id" = "item_id"))
# Remove any rows with missing scores
data <- na.omit(data)
# Split the data into training and testing sets
train_index <- createDataPartition(data$score_item, p = 0.8, list = FALSE)
train_data <- data[train_index, ]
test_data <- data[-train_index, ]
rf_model <- randomForest(score_item ~ ., data = train_data, ntree = 100)
rf_model <- randomForest(score_item ~ ., data = train_data, ntree = 100)
# Make predictions on the test set
predictions <- predict(rf_model, test_data)
predictions
# Calculate the RMSE
rmse <- sqrt(mean((predictions - test_data$score_item)^2))
print(paste("RMSE:", rmse))
# Calculate the R-squared value
r2 <- cor(predictions, test_data$score_item)^2
print(paste("R-squared:", r2))
# Split data 80-20 into training and test sets
train_index <- createDataPartition(data$score_item, p = 0.8, list = FALSE)
train_data <- data[train_index, ]
test_data <- data[-train_index, ]
# Train random forest model to predict item scores from features
rf_model <- randomForest(score_item ~ ., data = train_data, ntree = 100)
# Make predictions on test set
predictions <- predict(rf_model, test_data)
# Calculate and interpret model performance metrics
rmse <- sqrt(mean((predictions - test_data$score_item)^2))
r2 <- cor(predictions, test_data$score_item)^2
# Print model performance summary
print("Random Forest Model Performance:")
print(paste("RMSE:", round(rmse, 3),
"- Average prediction error in score units"))
print(paste("R-squared:", round(r2, 3),
"- Proportion of score variance explained"))
# Get feature importance
importance <- importance(rf_model)
imp_df <- data.frame(
Feature = rownames(importance),
Importance = importance[,1]
)
imp_df <- imp_df[order(-imp_df$Importance),]
print("\nTop 10 Most Important Features:")
print(head(imp_df, 10))
# Plot actual vs predicted scores
plot(test_data$score_item, predictions,
xlab = "Actual Scores",
ylab = "Predicted Scores",
main = "Model Predictions vs Actual Scores")
abline(0, 1, col = "red", lty = 2)
# Plot actual vs predicted scores
plot(test_data$score_item, predictions,
xlab = "Actual Scores",
ylab = "Predicted Scores",
main = "Model Predictions vs Actual Scores")
abline(0, 1, col = "red", lty = 2)
# Install and load mRMRe package if not already installed
if (!require("mRMRe")) {
install.packages("mRMRe")
library(mRMRe)
}
# Create mRMR.data object from training data
# First convert data to matrix format, excluding target variable
feature_matrix <- as.matrix(train_data[, !names(train_data) %in% c("score_item")])
target_vector <- train_data$score_item
mrmr_data <- mRMR.data(data = feature_matrix)
target_vector
mrmr_data <- mRMR.data(data = feature_matrix)
# Ensure that the feature matrix is a data frame
feature_matrix <- as.data.frame(train_data[, !names(train_data) %in% c("score_item")])
# Create mRMR.data object from training data
mrmr_data <- mRMR.data(data = feature_matrix)
# Create mRMR.data object from training data
mrmr_data <- mRMR.data(data = feature_matrix)
numeric_cols <- sapply(feature_matrix, function(x) {
is.numeric(x) || (is.factor(x) && is.ordered(x))
})
# Create mRMR.data object from training data
mrmr_data <- mRMR.data(data = feature_matrix)
# Ensure that the feature matrix is a data frame
feature_matrix <- as.data.frame(train_data[, !names(train_data) %in% c("score_item")])
# Filter out non-numeric/non-ordered columns from feature matrix
numeric_cols <- sapply(feature_matrix, is.numeric)
# Create mRMR.data object from training data
mrmr_data <- mRMR.data(data = numeric_cols)
# Ensure that the feature matrix is a data frame
feature_matrix <- as.data.frame(train_data[, !names(train_data) %in% c("score_item")])
# Filter out non-numeric/non-ordered columns from feature matrix
numeric_cols <- as.data.frame(sapply(feature_matrix, is.numeric))
# Create mRMR.data object from training data
mrmr_data <- mRMR.data(data = numeric_cols)
# Filter out non-numeric/non-ordered columns from feature matrix
numeric_cols <- sapply(feature_matrix, is.numeric)
# Ensure that the feature matrix is a data frame
feature_matrix <- as.data.frame(train_data[, !names(train_data) %in% c("score_item")])
# Filter out non-numeric/non-ordered columns from feature matrix
numeric_cols <- sapply(feature_matrix, is.numeric)
# Keep only numeric and ordered factor columns
feature_matrix <- feature_matrix[, numeric_cols]
# Create mRMR.data object from training data
mrmr_data <- mRMR.data(data = feature_matrix)
View(feature_matrix)
View(feature_matrix)
# Install and load mRMRe package if not already installed
if (!require("mRMRe")) {
install.packages("mRMRe")
library(mRMRe)
}
# Ensure that the feature matrix is a data frame
feature_matrix <- as.data.frame(train_data[, !names(train_data) %in% c("score_item")])
library(tidyverse)
# Install and load mRMRe package if not already installed
if (!require("mRMRe")) {
install.packages("mRMRe")
library(mRMRe)
}
# Load the data
data <- read.csv("item_features2.csv")
# Read in trial data
trials <- read_csv("/Users/davidwhyatt/Downloads/miq_trials.csv", n_max = 1e4) |>
filter(test == "mdt")
# Calculate mean score for each item
score_by_item <- trials |>
group_by(item_id) |>
summarise(
score_item = mean(score)
)
# Ensure that the feature matrix is a data frame
feature_matrix <- as.data.frame(data[, !names(data) %in% c("score_item")])
# Filter out non-numeric columns from feature matrix
numeric_cols <- sapply(feature_matrix, is.numeric)
# Convert any factor columns to numeric if necessary
factor_cols <- sapply(feature_matrix, is.factor)
feature_matrix[, factor_cols] <- lapply(feature_matrix[, factor_cols, drop = FALSE], function(x) {
as.numeric(as.character(x))
})
# Convert any factor columns to numeric if necessary
factor_cols <- sapply(feature_matrix, is.factor)
feature_matrix[, factor_cols] <- lapply(feature_matrix[, factor_cols, drop = FALSE], function(x) {
as.numeric(as.character(x))
})
# Keep only numeric columns
feature_matrix <- feature_matrix[, numeric_cols | factor_cols]
# Check if feature_matrix is empty after filtering
if (ncol(feature_matrix) == 0) {
stop("Feature matrix is empty after filtering non-numeric columns.")
}
View(feature_matrix)
mrmr_data <- mRMR.data(data = feature_matrix)
# Remove any features that are categorical
feature_matrix <- feature_matrix[, !sapply(feature_matrix, is.factor)]
# Create mRMR.data object from training data
mrmr_data <- mRMR.data(data = feature_matrix)
# Load the data
data <- read.csv("item_features2.csv")
# Read in trial data
trials <- read_csv("/Users/davidwhyatt/Downloads/miq_trials.csv", n_max = 1e4) |>
filter(test == "mdt")
# Calculate mean score for each item
score_by_item <- trials |>
group_by(item_id) |>
summarise(
score_item = mean(score)
)
# Ensure that the feature matrix is a data frame
feature_matrix <- as.data.frame(data[, !names(data) %in% c("score_item")])
# Filter out non-numeric columns from feature matrix
numeric_cols <- sapply(feature_matrix, is.numeric)
# Convert any factor columns to numeric if necessary
factor_cols <- sapply(feature_matrix, is.factor)
feature_matrix[, factor_cols] <- lapply(feature_matrix[, factor_cols, drop = FALSE], function(x) {
as.numeric(as.character(x))
})
# Keep only numeric columns
feature_matrix <- feature_matrix[, numeric_cols | factor_cols]
# Remove any features that are categorical
feature_matrix <- feature_matrix[, !sapply(feature_matrix, is.factor)]
# Keep only numeric columns
feature_matrix <- feature_matrix[, numeric_cols | factor_cols]
feature_matrix <- feature_matrix[, sapply(feature_matrix, function(x) length(unique(x)) > 2)]
mrmr_data <- mRMR.data(data = feature_matrix)
# Create mRMR.data object from training data
mrmr_data <- mRMR.data(data = feature_matrix)
# Create mRMR.data object from training data
mrmr_data <- mRMR.data(data = feature_matrix)
library(tidyverse)
# Install and load mRMRe package if not already installed
if (!require("mRMRe")) {
install.packages("mRMRe")
library(mRMRe)
}
# Load the data
data <- read.csv("item_features2.csv")
# Read in trial data
trials <- read_csv("/Users/davidwhyatt/Downloads/miq_trials.csv", n_max = 1e4) |>
filter(test == "mdt")
# Calculate mean score for each item
score_by_item <- trials |>
group_by(item_id) |>
summarise(
score_item = mean(score)
)
# Join scores to feature data
data <- data |>
left_join(score_by_item, by = c("melody_id" = "item_id"))
# Keep only numeric columns
numeric_cols <- sapply(data, is.numeric)
data <- data[, numeric_cols]
# Remove any columns with less than 3 unique values (binary/categorical)
data <- data[, sapply(data, function(x) length(unique(x)) > 2)]
# Remove any columns with NA values
data <- na.omit(data)
# Create mRMR.data object
mrmr_data <- mRMR.data(data = data)
